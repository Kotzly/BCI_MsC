{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "beb8869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from ica_benchmark.scoring import SCORING_FN_DICT, apply_pairwise_parallel\n",
    "from ica_benchmark.processing.ica import get_all_methods, get_ica_instance\n",
    "\n",
    "from ica_benchmark.io.load import BCI_IV_Comp_Dataset\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "\n",
    "from sacred.observers import MongoObserver, FileStorageObserver\n",
    "from sacred import Experiment\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from mne.decoding import CSP\n",
    "from mne.time_frequency import psd_multitaper, psd_welch\n",
    "\n",
    "def cue_name(cue):\n",
    "    return {\n",
    "        0: \"Left hand\",\n",
    "        1: \"Right hand\",\n",
    "        2: \"Foot\",\n",
    "        3: \"Tongue\",\n",
    "    }[cue]\n",
    "\n",
    "class ConcatenateChannelsPSD(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        super(ConcatenateChannelsPSD).__init__()\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        n = len(x)\n",
    "        return x.reshape(n, -1)\n",
    "\n",
    "\n",
    "class PSD(BaseEstimator):\n",
    "    BANDS_DICT = {\n",
    "#         \"delta\": (1, 4),\n",
    "#         \"theta\": (4, 8),\n",
    "        \"mu\": (8, 13),\n",
    "        \"beta\": (13, 25),\n",
    "#         \"gamma\": (25, 40)\n",
    "    }\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PSD).__init__()\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def set_params(**params):\n",
    "        for param in params:\n",
    "            assert params in [\"picks\", \"n_fft\", \"n_overlap\", \"n_per_seg\"]\n",
    "        self.kwargs.update(params)\n",
    "    \n",
    "    def get_params(self, *args, **kwargs):\n",
    "        return self.kwargs\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        if isinstance(x, list):\n",
    "            x = mne.concatenate_epochs(x)\n",
    "        psds, freqs = psd_welch(x, ** self.kwargs)\n",
    "        if (\"average\" in self.kwargs) and (self.kwargs[\"average\"] is None):\n",
    "            psds = psds.sum(axis=3)\n",
    "        self.freqs = freqs\n",
    "\n",
    "        band_spectras = list()\n",
    "        for band, (lfreq, hfreq) in self.BANDS_DICT.items():\n",
    "            band_spectra = psds[:, :, (freqs >= lfreq) & (freqs < hfreq)]\n",
    "            band_spectras.append(\n",
    "                band_spectra.mean(axis=2, keepdims=True)\n",
    "            )\n",
    "        \n",
    "        band_spectras = np.concatenate(band_spectras, axis=2)\n",
    "            \n",
    "        return band_spectras\n",
    "\n",
    "\n",
    "root = Path(\"/home/paulo/Documents/datasets/BCI_Comp_IV_2a/gdf/\")\n",
    "selected_channels = [\"EEG-Fz\", \"EEG-C3\", \"EEG-C4\", \"EEG-Pz\", \"EEG-Cz\"]\n",
    "filepaths = sorted(root.glob(\"A*T.gdf\"))\n",
    "\n",
    "# clf.predict(full_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abf0d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "TEST_LABEL_FOLDER = Path(\"/home/paulo/Documents/datasets/BCI_Comp_IV_2a/true_labels/\")\n",
    "DEFAULT_TIME_BANDS = [(3, 6)]\n",
    "def preprocess_epochs(epochs, timebands=None, car_filter=True):\n",
    "    if timebands is None:\n",
    "        timebands = DEFAULT_TIME_BANDS\n",
    "    epochs = epochs.copy()\n",
    "    \n",
    "    epochs.load_data()\n",
    "#     epochs.filter(5, 60)\n",
    "    \n",
    "    if car_filter:\n",
    "        epochs.set_eeg_reference(\"average\")\n",
    "    events = epochs.events[:, 2]\n",
    "#     epochs.drop(~((events == 0) | (events == 1)))\n",
    "\n",
    "    partial_epochs = list()\n",
    "#     for timeband in [(3, 5), (4, 6)]:\n",
    "#     for timeband in [(0, 2), (1, 3), (3, 5), (4, 6)]:\n",
    "#     for timeband in [(3, 4), (4, 5), (5, 6)]:\n",
    "    for timeband in [(3, 6)]:\n",
    "        partial_epochs.append(\n",
    "            epochs.copy().crop(*timeband).shift_time(-timeband[0])\n",
    "        )\n",
    "    epochs = mne.concatenate_epochs(partial_epochs).copy()\n",
    "    return epochs\n",
    "\n",
    "def load_subject_epochs(subject_number, test_label_folder=TEST_LABEL_FOLDER):\n",
    "    train_file_path = root / \"A{}T.gdf\".format(str(subject_number).rjust(2, \"0\"))\n",
    "    test_file_path = root / \"A{}E.gdf\".format(str(subject_number).rjust(2, \"0\"))\n",
    "    test_label_file_path = test_label_folder / \"A{}E.csv\".format(str(subject_number).rjust(2, \"0\"))\n",
    "    train_epochs = BCI_IV_Comp_Dataset.load_dataset(\n",
    "        [train_file_path],\n",
    "        reject=False,\n",
    "        as_epochs=True,\n",
    "        concatenate=False,\n",
    "        drop_bad=False,\n",
    "        return_metadata=False,\n",
    "        tmin=0.,\n",
    "        tmax=5.5,\n",
    "    )[0]\n",
    "    test_epochs = BCI_IV_Comp_Dataset.load_dataset(\n",
    "        [test_file_path],\n",
    "        reject=False,\n",
    "        as_epochs=True,\n",
    "        concatenate=False,\n",
    "        drop_bad=True,\n",
    "        return_metadata=False,\n",
    "        tmin=0.,\n",
    "        # The last timestamp does not exist, so MNE will ignore the last epoch because it will not end in 6s\n",
    "        # So here we use 5.5 seconds because there will always be 5.5 seconds after a event\n",
    "        tmax=5.5,\n",
    "        has_labels=False\n",
    "    )[0]\n",
    "\n",
    "    train_epochs = preprocess_epochs(train_epochs, car_filter=False)\n",
    "    test_epochs = preprocess_epochs(test_epochs, car_filter=False)\n",
    "    \n",
    "    train_epochs.drop_bad(dict(eeg=1e-4))\n",
    "\n",
    "    train_events = train_epochs.events[:, 2].flatten()\n",
    "    train_epochs.drop(~((train_events == 0) | (train_events == 1)))\n",
    "    train_labels = train_epochs.events[:, 2]\n",
    "    \n",
    "    test_labels = pd.read_csv(test_label_file_path, header=None).to_numpy().flatten() - 1\n",
    "    assert len(test_labels) == len(test_epochs), \"{} epochs | {} labels\".format(len(test_epochs), len(test_labels))\n",
    "    \n",
    "    test_epochs.events[:, 2] = test_labels\n",
    "    test_epochs.drop(~((test_labels == 0) | (test_labels == 1)))\n",
    "    test_labels = test_epochs.events[:, 2]\n",
    "\n",
    "    return (train_epochs, train_labels), (test_epochs, test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "98eca0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "\n",
    "def get_corr_features(x):\n",
    "    features = list()\n",
    "    for i in range(len(x)):\n",
    "        corr_matrix = np.corrcoef(x[i])\n",
    "        idx1, idx2 = np.triu_indices(corr_matrix.shape[0], 1)\n",
    "        features.append(\n",
    "            corr_matrix[idx1, idx2].reshape(1, -1)\n",
    "        )\n",
    "    return np.vstack(features)\n",
    "\n",
    "\n",
    "class CSPWrapper(BaseEstimator):\n",
    "    def __init__(self, n_components=4):\n",
    "        self.n_components = n_components\n",
    "        self.csp = None\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.csp = CSP(n_components=self.n_components)\n",
    "        self.csp.fit(x, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return self.csp.transform(x)\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        self.n_components = params[\"n_components\"]\n",
    "        self.csp = CSP(n_components=self.n_components)\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return dict(n_components=self.n_components)\n",
    "    \n",
    "def run(use_ica=True, use_csp=False, channels=None):\n",
    "    global train_epochs, train_labels, test_epochs, test_labels\n",
    "\n",
    "    scores_dict = dict(bas=list(), kappa=list(), acc=list())\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        print(filepath)\n",
    "        subject_number = int(filepath.name[1:3])\n",
    "        (train_epochs, train_labels), (test_epochs, test_labels) = load_subject_epochs(subject_number)\n",
    "        \n",
    "#         n_train = 3 * len(train_epochs) // 4\n",
    "#         test_epochs = train_epochs[n_train:]\n",
    "#         test_labels = train_labels[n_train:]\n",
    "#         train_epochs = train_epochs[:n_train]\n",
    "#         train_labels = train_labels[:n_train]\n",
    "\n",
    "        selected_channels = channels\n",
    "        if channels is None:\n",
    "            selected_channels = train_epochs.ch_names\n",
    "            \n",
    "        train_epochs.pick(selected_channels)\n",
    "        test_epochs.pick(selected_channels)\n",
    "        \n",
    "        ICA = get_ica_instance(\"jade\")\n",
    "        ica_channels = [\"ICA{}\".format(str(i).rjust(3, \"0\")) for i in range(len(selected_channels))]    \n",
    "\n",
    "        x_train, y_train = train_epochs, train_labels\n",
    "        x_test, y_test = test_epochs, test_labels\n",
    "\n",
    "        if use_ica:\n",
    "            ICA.fit(x_train)\n",
    "            x_train = ICA.transform(x_train)\n",
    "            x_test = ICA.transform(x_test)\n",
    "\n",
    "        if use_csp:\n",
    "            x_train = x_train.get_data()\n",
    "            x_test = x_test.get_data()\n",
    "            \n",
    "        print(filepath.name)\n",
    "        print(\"Train size\", len(x_train))\n",
    "        print(\"Test size\", len(x_test))\n",
    "        classifier = LDA(n_components=1)\n",
    "        SFS = SequentialFeatureSelector(\n",
    "            LDA(n_components=1),\n",
    "            direction='forward',\n",
    "            cv=4,\n",
    "            scoring=make_scorer(cohen_kappa_score, greater_is_better=True)\n",
    "        )\n",
    "        param_grid = dict(\n",
    "#             svc__C=np.logspace(-2, 2, 10),\n",
    "#             svc__C=[.01, .1, 1, 10],\n",
    "#             selectkbest__k=[10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, ]\n",
    "#             lineardiscriminantanalysis__n_components=[2, 4, 6]\n",
    "#             csp__n_components=[1, 2, 3, 4, 5]\n",
    "            sequentialfeatureselector__n_features_to_select=[1, 2, 3, 5, 15, 20],\n",
    "#             plscanonical__n_components=[1, 2, 3, 4, 5]\n",
    "        )\n",
    "        if not use_csp:\n",
    "            len_size = 250\n",
    "            psd = PSD(\n",
    "                picks=x_train.ch_names,\n",
    "                n_fft=1 * len_size,\n",
    "                n_overlap=len_size // 4,\n",
    "                n_per_seg=1 * len_size,\n",
    "                average=None,\n",
    "                window=\"hamming\",\n",
    "                proj=False\n",
    "            )\n",
    "            psd.fit(x_train)\n",
    "            x_train = psd.transform(x_train)\n",
    "            x_test = psd.transform(x_test)\n",
    "\n",
    "            # 2 classes\n",
    "            clf = make_pipeline(\n",
    "                ConcatenateChannelsPSD(),\n",
    "                StandardScaler(),\n",
    "                SFS,\n",
    "                classifier\n",
    "            )\n",
    "        else:\n",
    "            clf = make_pipeline(\n",
    "                CSPWrapper(),\n",
    "                StandardScaler(),\n",
    "                SFS,\n",
    "                classifier\n",
    "            )\n",
    "            param_grid.update(\n",
    "                csp__n_components=[1, 2, 3, 4, 5]\n",
    "            )\n",
    "            \n",
    "        gs_cv = GridSearchCV(\n",
    "            clf,\n",
    "            param_grid=param_grid,\n",
    "            cv=4,\n",
    "            scoring=make_scorer(cohen_kappa_score, greater_is_better=True),\n",
    "            error_score=-1,\n",
    "            refit=True,\n",
    "            n_jobs=3,\n",
    "            verbose=2\n",
    "        )\n",
    "        print(\"Fitting... \", end=\"\")\n",
    "        start = time.time()\n",
    "        gs_cv.fit(x_train, y_train)\n",
    "        print(\"Done (took {:.2f}s)\".format(time.time() - start))\n",
    "\n",
    "        pred  = gs_cv.predict(x_test)\n",
    "        bas = balanced_accuracy_score(y_test, pred)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        kappa = cohen_kappa_score(y_test, pred)\n",
    "\n",
    "        scores_dict[\"kappa\"].append(kappa)\n",
    "        scores_dict[\"acc\"].append(acc)\n",
    "        scores_dict[\"bas\"].append(bas)\n",
    "\n",
    "        print(\"Kappa\", kappa)\n",
    "        print(\"Accuracy\", acc)\n",
    "        print(\"BAS\", bas)\n",
    "        print(gs_cv.best_score_)\n",
    "        print(gs_cv.best_params_)\n",
    "        print(classification_report(y_test, pred), end=\"\\n\\n\")\n",
    "        \n",
    "\n",
    "    print(\n",
    "        \"Avg Kappa: {:.3f} (std. {:.3f})\".format(\n",
    "            np.mean(scores_dict[\"kappa\"]),\n",
    "            np.std(scores_dict[\"kappa\"]),\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1172dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paulo/Documents/datasets/BCI_Comp_IV_2a/gdf/A01T.gdf\n",
      "A01T.gdf\n",
      "Train size 112\n",
      "Test size 144\n",
      "Fitting... Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Done (took 32.11s)\n",
      "Kappa 0.05555555555555558\n",
      "Accuracy 0.5277777777777778\n",
      "BAS 0.5277777777777778\n",
      "0.12500000000000003\n",
      "{'sequentialfeatureselector__n_features_to_select': 15}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.42      0.47        72\n",
      "           1       0.52      0.64      0.57        72\n",
      "\n",
      "    accuracy                           0.53       144\n",
      "   macro avg       0.53      0.53      0.52       144\n",
      "weighted avg       0.53      0.53      0.52       144\n",
      "\n",
      "\n",
      "/home/paulo/Documents/datasets/BCI_Comp_IV_2a/gdf/A02T.gdf\n"
     ]
    }
   ],
   "source": [
    "run(use_ica=False, use_csp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ebcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(use_ica=True, use_csp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b923b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(use_ica=True, use_csp=False, channels=[\"EEG-C3\", \"EEG-C4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(use_ica=False, use_csp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(use_ica=False, use_csp=True, channels=[\"EEG-C3\", \"EEG-C4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f9542",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_epochs, train_labels), (test_epochs, test_labels) = load_subject_epochs(1)\n",
    "ICA = get_ica_instance(\"jade\")\n",
    "ica_channels = [\"ICA{}\".format(str(i).rjust(3, \"0\")) for i in range(len(selected_channels))]    \n",
    "\n",
    "x_train, y_train = train_epochs, train_labels\n",
    "x_test, y_test = test_epochs, test_labels\n",
    "\n",
    "ICA.fit(x_train)\n",
    "x_train = ICA.transform(x_train)\n",
    "x_test = ICA.transform(x_test)\n",
    "_, _, len_size = x_train.get_data().shape\n",
    "psd = PSD(\n",
    "    picks=x_train.ch_names,\n",
    "    n_fft=len_size // 2,\n",
    "    n_overlap=len_size // 3,\n",
    "    n_per_seg=len_size // 2,\n",
    "    average=None,\n",
    "    window=\"hamming\"\n",
    ")\n",
    "psd.fit(x_train)\n",
    "x_train = psd.transform(x_train)\n",
    "x_test = psd.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = dict()\n",
    "\n",
    "classifier = LDA(n_components=1)\n",
    "clf = make_pipeline(\n",
    "    ConcatenateChannelsPSD(),\n",
    "    PLSCanonical(n_components=1),\n",
    "    StandardScaler(),\n",
    "#     classifier\n",
    ")\n",
    "clf.fit(x_train, y_train)\n",
    "clf.transform(x_train).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
