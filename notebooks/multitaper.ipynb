{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "leading-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ica_benchmark.scoring import mutual_information, coherence, correntropy, apply_pairwise, apply_pairwise_parallel, SCORING_FN_DICT\n",
    "from ica_benchmark.processing.ica import get_ica_transformers\n",
    "import time\n",
    "from ica_benchmark.io.load import join_gdfs_to_numpy, load_subjects_data, load_subject_data\n",
    "from ica_benchmark.processing.label import get_annotations\n",
    "from mne import find_events, events_from_annotations\n",
    "from mne.viz import plot_events\n",
    "from mne.io import read_raw_gdf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demographic-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root = Path(\"/home/paulo/Documents/datasets/BCI_Comp_IV_2a/gdf/\")\n",
    "\n",
    "subjects =  {\n",
    "    \"A01\": [\n",
    "        root / \"A01T.gdf\",\n",
    "#         root / \"A01E.gdf\",\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prostate-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_subjects_data(root, subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "approximate-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = data[\"A01\"][\"gdf\"]._data.T\n",
    "labels = data[\"A01\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "surprising-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import psd_multitaper, tfr_array_multitaper, psd_array_multitaper\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ica_benchmark.processing.ica import create_gdf_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "local-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = np.expand_dims(arr.T, axis=0)\n",
    "# arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "convinced-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = tfr_array_multitaper(arr, 250, np.linspace(1, 12, 12), output=\"power\", n_cycles=3, decim=10)\n",
    "# res = res.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "paperback-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30, 5))\n",
    "# plt.imshow(res[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "polish-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(arr[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "allied-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset, DataLoader, Dataset\n",
    "import torch\n",
    "from statistics import mode\n",
    "\n",
    "DEFAULT_FREQUENCIES = np.linspace(3, 30, 10)\n",
    "\n",
    "DEFAULT_TRF_KWARGS = dict(\n",
    "    sfreq=250.0,\n",
    "    freqs=DEFAULT_FREQUENCIES, \n",
    "#     n_cycles=7.0,\n",
    "    n_cycles=3.0,\n",
    "    zero_mean=True,\n",
    "    time_bandwidth=4,\n",
    "#     use_fft=True,\n",
    "    decim=1,\n",
    "    output='power',\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "DEFAULT_PSD_KWARGS = dict(\n",
    "    sfreq=250.0,\n",
    "    fmin=0,\n",
    "    fmax=np.inf,\n",
    "    bandwidth=None,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "def tfr_multitaper(\n",
    "    arr,\n",
    "    epochs_mode=False,\n",
    "    feature_format=None,\n",
    "    cut_size=None,\n",
    "    **mne_kwargs\n",
    "):\n",
    "    \n",
    "    if not mne_kwargs:\n",
    "        mne_kwargs = DEFAULT_TRF_KWARGS\n",
    "    \n",
    "    # arr is (n_times, n_channels)\n",
    "    if not epochs_mode:\n",
    "        assert arr.ndim == 2, \"The input array must be of shape (n_times, n_channels)\"\n",
    "        # to (n_channels, n_times)\n",
    "        arr = np.expand_dims(arr.T, axis=0)\n",
    "    else:\n",
    "        assert arr.ndim == 3, \"The input array must be of shape (n_epochs, n_times, n_channels)\"\n",
    "        # to (n_epochs, n_channels, n_times)\n",
    "        arr = arr.transpose(0, 2, 1)\n",
    "    \n",
    "    # input (n_epochs, n_channels, n_times)\n",
    "    tfr_psd = tfr_array_multitaper(\n",
    "        arr,\n",
    "        **mne_kwargs\n",
    "    )\n",
    "    # output = (n_epochs, n_chans, n_freqs, n_times)\n",
    "    \n",
    "    if feature_format is None:\n",
    "        return tfr_psd\n",
    "    \n",
    "    n_epochs, n_chans, n_freqs, n_times = tfr_psd.shape\n",
    "    cut_size = n_times if cut_size is None else cut_size\n",
    "    if feature_format:\n",
    "        #(n_epochs, n_chans, n_freqs, n_times) -> (size, features)\n",
    "        tfr_psd = tfr_psd\\\n",
    "            .transpose(0, 3, 1, 2)\\\n",
    "            .reshape(n_epochs, n_times, n_chans * n_freqs)[:, -n_times:, :]\n",
    "            \n",
    "    else:\n",
    "        tfr_psd = tfr_psd.transpose(0, 3, 1, 2)[:, :, :, -n_times:]\n",
    "    \n",
    "        \n",
    "    tfr_psd = tfr_psd.squeeze() if n_epochs == 1 else tfr_psd\n",
    "    \n",
    "    return tfr_psd\n",
    "\n",
    "def psd_multitaper(\n",
    "    arr,\n",
    "    **mne_kwargs\n",
    "    ):\n",
    "\n",
    "    if not mne_kwargs:\n",
    "        mne_kwargs = DEFAULT_PSD_KWARGS\n",
    "\n",
    "    psd, freqs = psd_array_multitaper(\n",
    "        arr.T,\n",
    "        **mne_kwargs\n",
    "    )\n",
    "    psd = np.expand_dims(psd.T, axis=0)\n",
    "    \n",
    "    return psd, freqs\n",
    "\n",
    "def with_default(value, default):\n",
    "    return value if value is not None else default\n",
    "\n",
    "class WindowTransformer():\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_transform_fn,\n",
    "        label_transform_fn=mode,\n",
    "        window_size=250,\n",
    "        stride=125,\n",
    "        iterator_mode=False,\n",
    "        ):\n",
    "\n",
    "        self.feature_transform_fn = feature_transform_fn\n",
    "        self.label_transform_fn = label_transform_fn\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.iterator_mode = iterator_mode\n",
    "\n",
    "    def transform(self, x, y=None, start=None, end=None):\n",
    "        \n",
    "        size = len(x)\n",
    "        start, end = with_default(start, 0), with_default(end, size)\n",
    "\n",
    "        if y is not None:\n",
    "            assert len(x) == len(y), \"X and Y must have same sizes\"\n",
    "\n",
    "        if self.iterator_mode:\n",
    "            return self._transform_iter(x, y=y, start=start, end=end)\n",
    "        else:\n",
    "            return self._transform_list(x, y=y, start=start, end=end)\n",
    "\n",
    "    def _transform_list(self, x, y=None, start=None, end=None):\n",
    "        \n",
    "        with_y = y is not None\n",
    "\n",
    "        output_x, output_y = list(), list()\n",
    "\n",
    "        for step in range(start, end, self.stride):\n",
    "\n",
    "            if step + self.window_size > end:\n",
    "                break\n",
    "\n",
    "            item_x = self.feature_transform_fn(x[step : step + self.window_size])\n",
    "            if with_y:\n",
    "                item_y = self.label_transform_fn(y[step : step + self.window_size])\n",
    "            else:\n",
    "                item_y = None\n",
    "\n",
    "            return_items = item_x if with_y else (item_x, item_y)\n",
    "\n",
    "            output_x.append(item_x)\n",
    "            output_y.append(item_y)\n",
    "        \n",
    "        output_x = np.concatenate(output_x, axis=0)\n",
    "\n",
    "        if with_y:\n",
    "            output_y = np.array(output_y)\n",
    "\n",
    "        return (output_x, output_y) if with_y else output_x\n",
    "\n",
    "    def _transform_iter(self, x, y=None, start=None, end=None):\n",
    "        \n",
    "        with_y = y is not None\n",
    "        \n",
    "        if y is not None:\n",
    "            assert len(x) == len(y), \"X and Y must have same sizes\"\n",
    "\n",
    "        output_x, output_y = list(), list()\n",
    "\n",
    "        for step in range(start, end, self.stride):\n",
    "\n",
    "            if step + self.window_size > end:\n",
    "                break\n",
    "\n",
    "            item_x = self.feature_transform_fn(x[step : step + self.window_size])\n",
    "            if with_y:\n",
    "                item_y = self.label_transform_fn(y[step : step + self.window_size])\n",
    "            else:\n",
    "                item_y = None\n",
    "\n",
    "            return_items = (item_x, item_y) if with_y else item_x\n",
    "\n",
    "            yield return_items\n",
    "\n",
    "\n",
    "class IterDataset(IterableDataset):\n",
    "    def __init__(self, x, y, transformer_instance):\n",
    "        super(IterDataset).__init__()\n",
    "        self.transformer_instance = transformer_instance\n",
    "        self.start = 0\n",
    "        assert len(x) == len(y), \"Lengths must be equal\"\n",
    "        self.end = len(y)\n",
    "        self.x, self.y = x, y\n",
    "        \n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is None:  # single-process data loading, return the full iterator\n",
    "            iter_start, iter_end = self.start, self.end\n",
    "        else:  # in a worker process\n",
    "            # split workload\n",
    "            per_worker = int(np.ceil((self.end - self.start) / float(worker_info.num_workers)))\n",
    "            worker_id = worker_info.id\n",
    "            iter_start = self.start + worker_id * per_worker\n",
    "            iter_end = min(iter_start + per_worker, self.end)\n",
    "        \n",
    "        for x, y in self.transformer_instance.transform(self.x, self.y, start=iter_start, end=iter_end):\n",
    "            yield x, y\n",
    "\n",
    "            \n",
    "class MapDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y, transformer_instance):\n",
    "        super(MapDataset).__init__()\n",
    "        self.transformer_instance = transformer_instance\n",
    "        assert len(x) == len(y), \"Lengths must be equal\"\n",
    "        self.x, self.y = self.transformer_instance.transform(self.x, self.y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.i[i]\n",
    "\n",
    "class WindowTransformerDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X,\n",
    "        Y,\n",
    "        feature_transform_fn,\n",
    "        label_transform_fn=mode,\n",
    "        window_size=500,\n",
    "        stride=250,\n",
    "        start=None,\n",
    "        end=None\n",
    "        ):\n",
    "        super(WindowTransformerDataset).__init__()\n",
    "\n",
    "        self.feature_transform_fn = feature_transform_fn\n",
    "        self.label_transform_fn = label_transform_fn\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        assert len(X) == len(Y), \"X and Y must have same sizes.\"\n",
    "        assert len(X) >= window_size, \"Window size must be smaller than the array size.\"\n",
    "        self.X, self.Y = X, Y\n",
    "        \n",
    "        self.start = with_default(start, 0)\n",
    "        self.end = with_default(end, len(X))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.X) - self.window_size) // self.stride - 2\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        idx = i * self.stride\n",
    "\n",
    "        x = self.feature_transform_fn(self.X[idx : idx + self.window_size])\n",
    "        y = self.label_transform_fn(self.Y[idx : idx + self.window_size])\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "automotive-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_transform(x):\n",
    "    l = x[:, [3, 4, 5, 6, 7]]\n",
    "    l[:, -1] = (l[:, :4].max(axis=1) == 1).astype(np.uint32)\n",
    "    label = mode(l.argmax(1))\n",
    "    return label\n",
    "\n",
    "def psd_feature_transform(x, freqs=DEFAULT_FREQUENCIES, bandwidth=3):\n",
    "    psd, psd_freqs = psd_multitaper(x)\n",
    "    feature_vector = list()\n",
    "    for freq in freqs:\n",
    "        top_freq = freq + bandwidth / 2\n",
    "        bot_freq = freq - bandwidth / 2\n",
    "        selected_freqs = np.bitwise_and(psd_freqs >= bot_freq, psd_freqs <= top_freq)\n",
    "        feature = psd[:, selected_freqs, :].mean(axis=1)\n",
    "        feature_vector.append(feature)\n",
    "    \n",
    "    features = np.concatenate(feature_vector, axis=0).flatten()\n",
    "    return features\n",
    "        \n",
    "def feature_transform(x):\n",
    "    kwargs = DEFAULT_TRF_KWARGS.copy()\n",
    "    kwargs.update(dict(n_cycles=3, n_jobs=4))\n",
    "    return tfr_multitaper(\n",
    "        x,\n",
    "        epochs_mode=False,\n",
    "        feature_format=None,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "psd_fn = lambda x: psd_multitaper(x)[0]\n",
    "\n",
    "n = 30000\n",
    "\n",
    "# dataset = WindowTransformerDataset(arr, labels, tfr_multitaper, label_transform_fn=label_transform)\n",
    "dataset = WindowTransformerDataset(\n",
    "    arr,\n",
    "    labels,\n",
    "#     psd_feature_transform,\n",
    "    np.max,\n",
    "    label_transform_fn=label_transform,\n",
    "    window_size=250,\n",
    "    stride=100\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4, \n",
    "    drop_last=True,\n",
    "    prefetch_factor=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "caring-philippines",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# print(len(dataset))\n",
    "for x, y in dataset:\n",
    "#     print(x.shape, y.shape)\n",
    "    if y not in (0,):\n",
    "        print(y)\n",
    "#     plt.clf()\n",
    "#     plt.figure(figsize=(30, 5))\n",
    "#     p = x.numpy()[0, 0].transpose(1, 2, 0)[:, :300, :3]\n",
    "#     p = (p - p.min())/ (p.max() - p.min())\n",
    "#     plt.imshow(p)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "53241924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), array([300]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels[96300:96600, [3, 4, 5, 6]].argmax(axis=1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "36b3bd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e8902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "0 200\n",
    "200 300\n",
    "400 500\n",
    "600 700\n",
    "800 90/;.ç0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ce6fa775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220,)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psd_feature_transform(arr[:1000]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
