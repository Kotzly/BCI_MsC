{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comfortable-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "annotation_desc_dict = {\n",
    "    276: \"Idling EEG (eyes open)\",\n",
    "    277: \"Idling EEG (eyes closed)\",\n",
    "    768: \"Start of a trial\",\n",
    "    769: \"Cue onset left (class 1)\",\n",
    "    770: \"Cue onset right (class 2)\",\n",
    "    771: \"Cue onset foot (class 3)\",\n",
    "    772: \"Cue onset tongue (class 4)\",\n",
    "    783: \"Cue unknown\",\n",
    "    1023: \"Rejected trial\",\n",
    "    1072: \"Eye movements\",\n",
    "    32766: \"Start of a new run\",\n",
    "}\n",
    "\n",
    "annotation_encode_dict = {\n",
    "    276: 0,\n",
    "    277: 1,\n",
    "    768: 2,\n",
    "    769: 3,\n",
    "    770: 4,\n",
    "    771: 5,\n",
    "    772: 6,\n",
    "    783: 7,\n",
    "    1023: 8,\n",
    "    1072: 9,\n",
    "    32766: 10,\n",
    "}\n",
    "\n",
    "def get_annotations(data):\n",
    "    sr = data.info[\"sfreq\"]\n",
    "    n_samples = data._raw_extras[0][\"n_records\"]\n",
    "\n",
    "    onsets = np.trunc(data.annotations.onset * sr).astype(np.uint32, casting=\"unsafe\")\n",
    "    durations = np.trunc(data.annotations.duration * sr).astype(np.uint32, casting=\"unsafe\")\n",
    "    \n",
    "    desc = data.annotations.description.astype(np.uint32)\n",
    "    labels_codes = np.vectorize(annotation_encode_dict.get)(desc)\n",
    "    \n",
    "    n_codes = len(annotation_encode_dict)\n",
    "    labels = np.zeros((n_samples, n_codes))\n",
    "    \n",
    "    for code, onset, duration in zip(labels_codes, onsets, durations):\n",
    "        labels[onset:onset+duration, code] = 1\n",
    "    \n",
    "    return labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enclosed-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.io import read_raw_gdf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "root = Path(\"C:/Users/paull/Documents/GIT/BCI_MsC/notebooks/BCI_Comp_IV_2a/BCICIV_2a_gdf\")\n",
    "\n",
    "dataset_folder = root\n",
    "mat_files = list(dataset_folder.iterdir())\n",
    "\n",
    "PRELOAD = False\n",
    "\n",
    "def load_gdf_file(filepath):\n",
    "    gdf_data = read_raw_gdf(filepath, preload=PRELOAD)\n",
    "\n",
    "    chs = gdf_data.ch_names\n",
    "\n",
    "    gdf_data = read_raw_gdf(\n",
    "        filepath,\n",
    "        preload=True,\n",
    "        eog=[\"EOG-left\", \"EOG-central\", \"EOG-right\"],\n",
    "        exclude=[x for x in chs if \"EOG\" in x]\n",
    "    )\n",
    "    ch_names = gdf_data.ch_names\n",
    "    info = parse_info(\n",
    "        gdf_data._raw_extras[0][\"subject_info\"]\n",
    "    )\n",
    "    \n",
    "    labels = get_annotations(gdf_data)\n",
    "    \n",
    "    return gdf_data, labels, ch_names, info\n",
    "\n",
    "def parse_info(info_dict):\n",
    "    cols = ['id', 'smoking', 'alcohol_abuse', 'drug_abuse', 'medication', 'weight', 'height', 'sex', 'handedness', 'age']\n",
    "    parsed_info = {k:v for k, v in info_dict.items() if k in cols}\n",
    "    return parsed_info\n",
    "     \n",
    "def load_subject_data(root, subject, mode=None):\n",
    "    if mode is None:\n",
    "        mode = \"train\"\n",
    "    \n",
    "    if mode == \"train\":\n",
    "        filepath = root / f\"{subject}T.gdf\"\n",
    "        gdf_data, labels, ch_names, info = load_gdf_file(filepath)\n",
    "    elif mode == \"test\":\n",
    "        filepath = root / f\"{subject}E.gdf\"\n",
    "        gdf_data, labels, ch_names, info = load_gdf_file(filepath)\n",
    "    elif mode == \"both\":\n",
    "        filepath_t = root / f\"{subject}T.gdf\"\n",
    "        filepath_e = root / f\"{subject}E.gdf\"\n",
    "        gdf_data_t, labels_t, ch_names_t, info_t = load_gdf_file(filepath_t)\n",
    "        gdf_data_e, labels_e, ch_names, info = load_gdf_file(filepath_e)\n",
    "        \n",
    "        \n",
    "        assert np.all(ch_names_t == ch_names)\n",
    "        assert np.all(info_t == info)\n",
    "        \n",
    "        gdf_data = gdf_data_t.copy()\n",
    "        gdf_data._data = np.concatenate(\n",
    "            [\n",
    "                gdf_data_t._data,\n",
    "                gdf_data_e._data,\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        labels = np.concatenate(\n",
    "            [\n",
    "                labels_t,\n",
    "                labels_e\n",
    "            ],\n",
    "            axis=0\n",
    "        )\n",
    "    \n",
    "    return gdf_data, labels, ch_names, info\n",
    "\n",
    "def load_subjects_data(root, datasets=None, mode=\"train\"):\n",
    "    if datasets is None:\n",
    "#         data_dict = {\n",
    "#             \"all\": {\n",
    "#                 filepath.name[:3]: None for filepath in root.glob(\"*T.gdf\")\n",
    "#             }\n",
    "#         }\n",
    "        data_dict = {\n",
    "            filepath.name[:3]: {\n",
    "                filepath.name[:3]: None\n",
    "            } for filepath in root.glob(\"*T.gdf\")\n",
    "        }\n",
    "    else:\n",
    "        data_dict = {\n",
    "            dataset: {\n",
    "                subject_id: {} for subject_id in datasets[dataset]\n",
    "            } for dataset in datasets\n",
    "        }\n",
    "    \n",
    "    chs_ = None\n",
    "    for dataset in data_dict:\n",
    "        for subject_id in data_dict[dataset]:\n",
    "            gdf, labels, chs, info = load_subject_data(root, subject_id, mode=mode)\n",
    "            if chs_ is None:\n",
    "                chs_ = chs\n",
    "            else:\n",
    "                assert chs_ == chs\n",
    "            data_dict[dataset][subject_id] = {\n",
    "                \"gdf\": gdf,\n",
    "                \"chs\": chs,\n",
    "                \"info\": info,\n",
    "                \"labels\": labels\n",
    "            }\n",
    "    \n",
    "    \n",
    "    return data_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "resident-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {\n",
    "    \"train\": [\"A02\", \"A07\", \"A09\", \"A01\"],\n",
    "    \"validation\": [\"A03\", \"A06\"],\n",
    "    \"test\": [\"A04\", \"A05\"],\n",
    "}\n",
    "all_subjects = [f\"A0{i}\" for i in range(10)]\n",
    "\n",
    "dataset_dict = {\n",
    "    \"train\": [\"A02\", \"A07\"],\n",
    "    \"validation\": [\"A03\"],\n",
    "    \"test\": [\"A04\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inner-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "def get_kwargs(m, is_extended=False):\n",
    "    if is_extended:\n",
    "        return dict(method=m, fit_params=dict(extended=True))\n",
    "    return dict(method=m)\n",
    "\n",
    "ica_kwargs_dict = {\n",
    "    \"fastica\": get_kwargs(\"fastica\"),\n",
    "    \"infomax\": get_kwargs(\"infomax\"),\n",
    "    \"picard\": get_kwargs(\"picard\"),\n",
    "    \"ext_infomax\": get_kwargs(\"infomax\", is_extended=True),\n",
    "    \"ext_picard\": get_kwargs(\"picard\", is_extended=True)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "south-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import mutual_information, coherence, correntropy, apply_pairwise, apply_pairwise_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-anxiety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:13: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(filepath, preload=PRELOAD)\n",
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:17: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A02E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A02E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 662665  =      0.000 ...  2650.660 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:13: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(filepath, preload=PRELOAD)\n",
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:17: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 681070  =      0.000 ...  2724.280 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:13: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(filepath, preload=PRELOAD)\n",
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:17: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A07E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A07E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673134  =      0.000 ...  2692.536 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:13: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(filepath, preload=PRELOAD)\n",
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:17: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660529  =      0.000 ...  2642.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:13: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(filepath, preload=PRELOAD)\n",
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:17: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A03E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A03E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 648774  =      0.000 ...  2595.096 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:13: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(filepath, preload=PRELOAD)\n",
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:17: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A04T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A04T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 600914  =      0.000 ...  2403.656 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:13: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(filepath, preload=PRELOAD)\n",
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:17: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A04E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\paull\\Documents\\GIT\\BCI_MsC\\notebooks\\BCI_Comp_IV_2a\\BCICIV_2a_gdf\\A04E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660046  =      0.000 ...  2640.184 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:13: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(filepath, preload=PRELOAD)\n",
      "C:\\Users\\paull\\anaconda3\\envs\\bci\\lib\\site-packages\\mne\\io\\edf\\edf.py:1044: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "<ipython-input-2-17f0d3bb7d79>:17: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  gdf_data = read_raw_gdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 4 components\n",
      "Fitting ICA took 5.3s.\n",
      "('MI', 'fastica', 'test', 'A04', 0, 4)\n",
      "('correntropy', 'fastica', 'test', 'A04', 0, 4)\n",
      "('coherence', 'fastica', 'test', 'A04', 0, 4)\n",
      "('MI', 'fastica', 'validation', 'A03', 0, 4)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 0, 4)\n",
      "('coherence', 'fastica', 'validation', 'A03', 0, 4)\n",
      "('MI', 'fastica', 'train', 'A02', 0, 4)\n",
      "('correntropy', 'fastica', 'train', 'A02', 0, 4)\n",
      "('coherence', 'fastica', 'train', 'A02', 0, 4)\n",
      "('MI', 'fastica', 'train', 'A07', 0, 4)\n",
      "('correntropy', 'fastica', 'train', 'A07', 0, 4)\n",
      "('coherence', 'fastica', 'train', 'A07', 0, 4)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 4 components\n",
      "Fitting ICA took 3.8s.\n",
      "('MI', 'fastica', 'test', 'A04', 1, 4)\n",
      "('correntropy', 'fastica', 'test', 'A04', 1, 4)\n",
      "('coherence', 'fastica', 'test', 'A04', 1, 4)\n",
      "('MI', 'fastica', 'validation', 'A03', 1, 4)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 1, 4)\n",
      "('coherence', 'fastica', 'validation', 'A03', 1, 4)\n",
      "('MI', 'fastica', 'train', 'A02', 1, 4)\n",
      "('correntropy', 'fastica', 'train', 'A02', 1, 4)\n",
      "('coherence', 'fastica', 'train', 'A02', 1, 4)\n",
      "('MI', 'fastica', 'train', 'A07', 1, 4)\n",
      "('correntropy', 'fastica', 'train', 'A07', 1, 4)\n",
      "('coherence', 'fastica', 'train', 'A07', 1, 4)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 4 components\n",
      "Fitting ICA took 2.5s.\n",
      "('MI', 'fastica', 'test', 'A04', 2, 4)\n",
      "('correntropy', 'fastica', 'test', 'A04', 2, 4)\n",
      "('coherence', 'fastica', 'test', 'A04', 2, 4)\n",
      "('MI', 'fastica', 'validation', 'A03', 2, 4)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 2, 4)\n",
      "('coherence', 'fastica', 'validation', 'A03', 2, 4)\n",
      "('MI', 'fastica', 'train', 'A02', 2, 4)\n",
      "('correntropy', 'fastica', 'train', 'A02', 2, 4)\n",
      "('coherence', 'fastica', 'train', 'A02', 2, 4)\n",
      "('MI', 'fastica', 'train', 'A07', 2, 4)\n",
      "('correntropy', 'fastica', 'train', 'A07', 2, 4)\n",
      "('coherence', 'fastica', 'train', 'A07', 2, 4)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 8 components\n",
      "Fitting ICA took 3.8s.\n",
      "('MI', 'fastica', 'test', 'A04', 0, 8)\n",
      "('correntropy', 'fastica', 'test', 'A04', 0, 8)\n",
      "('coherence', 'fastica', 'test', 'A04', 0, 8)\n",
      "('MI', 'fastica', 'validation', 'A03', 0, 8)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 0, 8)\n",
      "('coherence', 'fastica', 'validation', 'A03', 0, 8)\n",
      "('MI', 'fastica', 'train', 'A02', 0, 8)\n",
      "('correntropy', 'fastica', 'train', 'A02', 0, 8)\n",
      "('coherence', 'fastica', 'train', 'A02', 0, 8)\n",
      "('MI', 'fastica', 'train', 'A07', 0, 8)\n",
      "('correntropy', 'fastica', 'train', 'A07', 0, 8)\n",
      "('coherence', 'fastica', 'train', 'A07', 0, 8)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 8 components\n",
      "Fitting ICA took 5.4s.\n",
      "('MI', 'fastica', 'test', 'A04', 1, 8)\n",
      "('correntropy', 'fastica', 'test', 'A04', 1, 8)\n",
      "('coherence', 'fastica', 'test', 'A04', 1, 8)\n",
      "('MI', 'fastica', 'validation', 'A03', 1, 8)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 1, 8)\n",
      "('coherence', 'fastica', 'validation', 'A03', 1, 8)\n",
      "('MI', 'fastica', 'train', 'A02', 1, 8)\n",
      "('correntropy', 'fastica', 'train', 'A02', 1, 8)\n",
      "('coherence', 'fastica', 'train', 'A02', 1, 8)\n",
      "('MI', 'fastica', 'train', 'A07', 1, 8)\n",
      "('correntropy', 'fastica', 'train', 'A07', 1, 8)\n",
      "('coherence', 'fastica', 'train', 'A07', 1, 8)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 8 components\n",
      "Fitting ICA took 4.5s.\n",
      "('MI', 'fastica', 'test', 'A04', 2, 8)\n",
      "('correntropy', 'fastica', 'test', 'A04', 2, 8)\n",
      "('coherence', 'fastica', 'test', 'A04', 2, 8)\n",
      "('MI', 'fastica', 'validation', 'A03', 2, 8)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 2, 8)\n",
      "('coherence', 'fastica', 'validation', 'A03', 2, 8)\n",
      "('MI', 'fastica', 'train', 'A02', 2, 8)\n",
      "('correntropy', 'fastica', 'train', 'A02', 2, 8)\n",
      "('coherence', 'fastica', 'train', 'A02', 2, 8)\n",
      "('MI', 'fastica', 'train', 'A07', 2, 8)\n",
      "('correntropy', 'fastica', 'train', 'A07', 2, 8)\n",
      "('coherence', 'fastica', 'train', 'A07', 2, 8)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 12 components\n",
      "Fitting ICA took 6.6s.\n",
      "('MI', 'fastica', 'test', 'A04', 0, 12)\n",
      "('correntropy', 'fastica', 'test', 'A04', 0, 12)\n",
      "('coherence', 'fastica', 'test', 'A04', 0, 12)\n",
      "('MI', 'fastica', 'validation', 'A03', 0, 12)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 0, 12)\n",
      "('coherence', 'fastica', 'validation', 'A03', 0, 12)\n",
      "('MI', 'fastica', 'train', 'A02', 0, 12)\n",
      "('correntropy', 'fastica', 'train', 'A02', 0, 12)\n",
      "('coherence', 'fastica', 'train', 'A02', 0, 12)\n",
      "('MI', 'fastica', 'train', 'A07', 0, 12)\n",
      "('correntropy', 'fastica', 'train', 'A07', 0, 12)\n",
      "('coherence', 'fastica', 'train', 'A07', 0, 12)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 12 components\n",
      "Fitting ICA took 9.2s.\n",
      "('MI', 'fastica', 'test', 'A04', 1, 12)\n",
      "('correntropy', 'fastica', 'test', 'A04', 1, 12)\n",
      "('coherence', 'fastica', 'test', 'A04', 1, 12)\n",
      "('MI', 'fastica', 'validation', 'A03', 1, 12)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 1, 12)\n",
      "('coherence', 'fastica', 'validation', 'A03', 1, 12)\n",
      "('MI', 'fastica', 'train', 'A02', 1, 12)\n",
      "('correntropy', 'fastica', 'train', 'A02', 1, 12)\n",
      "('coherence', 'fastica', 'train', 'A02', 1, 12)\n",
      "('MI', 'fastica', 'train', 'A07', 1, 12)\n",
      "('correntropy', 'fastica', 'train', 'A07', 1, 12)\n",
      "('coherence', 'fastica', 'train', 'A07', 1, 12)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 12 components\n",
      "Fitting ICA took 5.2s.\n",
      "('MI', 'fastica', 'test', 'A04', 2, 12)\n",
      "('correntropy', 'fastica', 'test', 'A04', 2, 12)\n",
      "('coherence', 'fastica', 'test', 'A04', 2, 12)\n",
      "('MI', 'fastica', 'validation', 'A03', 2, 12)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 2, 12)\n",
      "('coherence', 'fastica', 'validation', 'A03', 2, 12)\n",
      "('MI', 'fastica', 'train', 'A02', 2, 12)\n",
      "('correntropy', 'fastica', 'train', 'A02', 2, 12)\n",
      "('coherence', 'fastica', 'train', 'A02', 2, 12)\n",
      "('MI', 'fastica', 'train', 'A07', 2, 12)\n",
      "('correntropy', 'fastica', 'train', 'A07', 2, 12)\n",
      "('coherence', 'fastica', 'train', 'A07', 2, 12)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 16 components\n",
      "Fitting ICA took 15.0s.\n",
      "('MI', 'fastica', 'test', 'A04', 0, 16)\n",
      "('correntropy', 'fastica', 'test', 'A04', 0, 16)\n",
      "('coherence', 'fastica', 'test', 'A04', 0, 16)\n",
      "('MI', 'fastica', 'validation', 'A03', 0, 16)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 0, 16)\n",
      "('coherence', 'fastica', 'validation', 'A03', 0, 16)\n",
      "('MI', 'fastica', 'train', 'A02', 0, 16)\n",
      "('correntropy', 'fastica', 'train', 'A02', 0, 16)\n",
      "('coherence', 'fastica', 'train', 'A02', 0, 16)\n",
      "('MI', 'fastica', 'train', 'A07', 0, 16)\n",
      "('correntropy', 'fastica', 'train', 'A07', 0, 16)\n",
      "('coherence', 'fastica', 'train', 'A07', 0, 16)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 16 components\n",
      "Fitting ICA took 12.5s.\n",
      "('MI', 'fastica', 'test', 'A04', 1, 16)\n",
      "('correntropy', 'fastica', 'test', 'A04', 1, 16)\n",
      "('coherence', 'fastica', 'test', 'A04', 1, 16)\n",
      "('MI', 'fastica', 'validation', 'A03', 1, 16)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 1, 16)\n",
      "('coherence', 'fastica', 'validation', 'A03', 1, 16)\n",
      "('MI', 'fastica', 'train', 'A02', 1, 16)\n",
      "('correntropy', 'fastica', 'train', 'A02', 1, 16)\n",
      "('coherence', 'fastica', 'train', 'A02', 1, 16)\n",
      "('MI', 'fastica', 'train', 'A07', 1, 16)\n",
      "('correntropy', 'fastica', 'train', 'A07', 1, 16)\n",
      "('coherence', 'fastica', 'train', 'A07', 1, 16)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 16 components\n",
      "Fitting ICA took 18.7s.\n",
      "('MI', 'fastica', 'test', 'A04', 2, 16)\n",
      "('correntropy', 'fastica', 'test', 'A04', 2, 16)\n",
      "('coherence', 'fastica', 'test', 'A04', 2, 16)\n",
      "('MI', 'fastica', 'validation', 'A03', 2, 16)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 2, 16)\n",
      "('coherence', 'fastica', 'validation', 'A03', 2, 16)\n",
      "('MI', 'fastica', 'train', 'A02', 2, 16)\n",
      "('correntropy', 'fastica', 'train', 'A02', 2, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('coherence', 'fastica', 'train', 'A02', 2, 16)\n",
      "('MI', 'fastica', 'train', 'A07', 2, 16)\n",
      "('correntropy', 'fastica', 'train', 'A07', 2, 16)\n",
      "('coherence', 'fastica', 'train', 'A07', 2, 16)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 15.8s.\n",
      "('MI', 'fastica', 'test', 'A04', 0, 20)\n",
      "('correntropy', 'fastica', 'test', 'A04', 0, 20)\n",
      "('coherence', 'fastica', 'test', 'A04', 0, 20)\n",
      "('MI', 'fastica', 'validation', 'A03', 0, 20)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 0, 20)\n",
      "('coherence', 'fastica', 'validation', 'A03', 0, 20)\n",
      "('MI', 'fastica', 'train', 'A02', 0, 20)\n",
      "('correntropy', 'fastica', 'train', 'A02', 0, 20)\n",
      "('coherence', 'fastica', 'train', 'A02', 0, 20)\n",
      "('MI', 'fastica', 'train', 'A07', 0, 20)\n",
      "('correntropy', 'fastica', 'train', 'A07', 0, 20)\n",
      "('coherence', 'fastica', 'train', 'A07', 0, 20)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 29.5s.\n",
      "('MI', 'fastica', 'test', 'A04', 1, 20)\n",
      "('correntropy', 'fastica', 'test', 'A04', 1, 20)\n",
      "('coherence', 'fastica', 'test', 'A04', 1, 20)\n",
      "('MI', 'fastica', 'validation', 'A03', 1, 20)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 1, 20)\n",
      "('coherence', 'fastica', 'validation', 'A03', 1, 20)\n",
      "('MI', 'fastica', 'train', 'A02', 1, 20)\n",
      "('correntropy', 'fastica', 'train', 'A02', 1, 20)\n",
      "('coherence', 'fastica', 'train', 'A02', 1, 20)\n",
      "('MI', 'fastica', 'train', 'A07', 1, 20)\n",
      "('correntropy', 'fastica', 'train', 'A07', 1, 20)\n",
      "('coherence', 'fastica', 'train', 'A07', 1, 20)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 14.0s.\n",
      "('MI', 'fastica', 'test', 'A04', 2, 20)\n",
      "('correntropy', 'fastica', 'test', 'A04', 2, 20)\n",
      "('coherence', 'fastica', 'test', 'A04', 2, 20)\n",
      "('MI', 'fastica', 'validation', 'A03', 2, 20)\n",
      "('correntropy', 'fastica', 'validation', 'A03', 2, 20)\n",
      "('coherence', 'fastica', 'validation', 'A03', 2, 20)\n",
      "('MI', 'fastica', 'train', 'A02', 2, 20)\n",
      "('correntropy', 'fastica', 'train', 'A02', 2, 20)\n",
      "('coherence', 'fastica', 'train', 'A02', 2, 20)\n",
      "('MI', 'fastica', 'train', 'A07', 2, 20)\n",
      "('correntropy', 'fastica', 'train', 'A07', 2, 20)\n",
      "('coherence', 'fastica', 'train', 'A07', 2, 20)\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 22 components\n",
      "Fitting ICA took 15.1s.\n",
      "('MI', 'fastica', 'test', 'A04', 0, 22)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def join_gdfs(data_dict, datasets_names=None):\n",
    "    new_dict = {}\n",
    "    if datasets_names is None:\n",
    "        datasets_names = data_dict.keys()\n",
    "    \n",
    "    for dataset_name in datasets_names:\n",
    "        all_gdfs = []\n",
    "        all_labels = []\n",
    "        for subject_id in data_dict[dataset_name]:\n",
    "            all_gdfs.append(data_dict[dataset_name][subject_id][\"gdf\"])\n",
    "            all_labels.append(data_dict[dataset_name][subject_id][\"labels\"])\n",
    "\n",
    "        labels = np.concatenate(all_labels, axis=0)\n",
    "        gdf_base = all_gdfs[0].copy()\n",
    "        for gdf in all_gdfs[1:]:\n",
    "            gdf_base._data = np.concatenate(\n",
    "                [\n",
    "                    gdf_base._data,\n",
    "                    gdf._data\n",
    "                ],\n",
    "                axis=1\n",
    "            )\n",
    "        new_dict[dataset_name] = {\n",
    "            \"all\": {\n",
    "                \"gdf\": gdf_base,\n",
    "                \"labels\": labels,\n",
    "                \"info\": None,\n",
    "                \"chs\": gdf_base.ch_names\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    return new_dict\n",
    "        \n",
    "N_RUNS = 3\n",
    "\n",
    "results = {}\n",
    "\n",
    "fn_dict = {\n",
    "    \"MI\": mutual_information,\n",
    "    \"correntropy\": correntropy,\n",
    "    \"coherence\": coherence\n",
    "}\n",
    "\n",
    "n_components_list = [4, 8, 12, 16, 20, 22]\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    datasets\n",
    "except:\n",
    "    datasets = load_subjects_data(root, datasets=dataset_dict, mode=\"both\")\n",
    "\n",
    "score_calculated_before = {}\n",
    "\n",
    "for ica_method in ica_kwargs_dict:\n",
    "    for n_components in n_components_list:\n",
    "        for run_n in range(N_RUNS):\n",
    "            \n",
    "            joined_dataset = join_gdfs(datasets, [\"train\"])\n",
    "\n",
    "            gdf_data = joined_dataset[\"train\"][\"all\"][\"gdf\"]\n",
    "            ica_transform = mne.preprocessing.ICA(n_components=n_components, **ica_kwargs_dict[ica_method])\n",
    "            ica_transform = ica_transform.fit(gdf_data)\n",
    "            \n",
    "            del joined_dataset\n",
    "\n",
    "            for dataset_name in (\"test\", \"validation\", \"train\"):\n",
    "\n",
    "                for subject_id in datasets[dataset_name]:\n",
    "                    \n",
    "\n",
    "                    gdf_data = datasets[dataset_name][subject_id][\"gdf\"]   \n",
    "                    \n",
    "                    data_after = ica_transform.get_sources(gdf_data).get_data().T\n",
    "\n",
    "                    for fn_name in fn_dict:\n",
    "\n",
    "                        print((fn_name, ica_method, dataset_name, subject_id, run_n, n_components))\n",
    "                        \n",
    "                        if (n_components > 5) or len(data_after) > 2e6:\n",
    "                            apply_fn = apply_pairwise_parallel\n",
    "                        else:\n",
    "                            apply_fn = apply_pairwise\n",
    "                        \n",
    "                        if not (subject_id, fn_name) in score_calculated_before:\n",
    "                            data_before = gdf_data.get_data().T\n",
    "                            score_before = apply_pairwise_parallel(data_before, fn_dict[fn_name])\n",
    "                            score_calculated_before[(subject_id, fn_name)] = score_before\n",
    "\n",
    "                        start = time.time()\n",
    "                        score_after = apply_fn(data_after, fn_dict[fn_name])\n",
    "                        duration = time.time() - start\n",
    "                        \n",
    "                        results[(fn_name, ica_method, dataset_name, subject_id, run_n, n_components)] = {\n",
    "                            \"score_before\": score_calculated_before[(subject_id, fn_name)],\n",
    "                            \"score_after\": score_after,\n",
    "                            \"time\": duration\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = []\n",
    "cols = [\"scoring\", \"algorithm\", \"dataset\", \"subject_id\", \"run\", \"n_components\", \"score_before\", \"score_after\", \"time\"]\n",
    "\n",
    "for k, v in results.items():\n",
    "    df.append(list(k) + list(v.values()))\n",
    "pd.DataFrame(df, columns=cols).to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df, columns=cols)\n",
    "df.groupby([\"scoring\", \"algorithm\", \"dataset\", \"subject_id\", \"n_components\"]).mean().query(\"\"\" (dataset == \"test\") \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "10 + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-medium",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
